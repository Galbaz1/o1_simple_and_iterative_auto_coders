Here is a fully functioning FastAPI chat application that allows users to upload a PDF file and responds with a summary of its contents using OpenAI's GPT-4 model. The application handles large PDFs by splitting the text into manageable chunks, summarizes each chunk, and then combines these summaries into a final summary.



**Instructions to Run the Application:**

1. **Install Required Packages:**

   Make sure you have Python 3.7 or later installed. Install the required packages using pip:

   ```bash
   pip install fastapi uvicorn PyPDF2 openai tiktoken
   ```

2. **Set Your OpenAI API Key:**

   Export your OpenAI API key as an environment variable:

   ```bash
   export OPENAI_API_KEY='your-api-key-here'
   ```

   Replace `'your-api-key-here'` with your actual OpenAI API key.

3. **Run the Application:**

   Start the FastAPI application using Uvicorn:

   ```bash
   uvicorn main:app --reload
   ```

   The `--reload` flag will auto-reload the server if you make changes to the code.

4. **Interact with the API:**

   Once the server is running, you can interact with the API by sending a POST request to `/summarize_pdf/`. You can use tools like [HTTPie](https://httpie.io/), [cURL](https://curl.se/), or create a simple HTML frontend.

   **Example using cURL:**

   ```bash
   curl -X POST "http://127.0.0.1:8000/summarize_pdf/" \
        -H "accept: application/json" \
        -H "Content-Type: multipart/form-data" \
        -F "file=@/path/to/your/document.pdf"
   ```

   Replace `"/path/to/your/document.pdf"` with the actual path to the PDF file you want to summarize.

5. **API Response:**

   The API will return a JSON response containing the summary:

   ```json
   {
     "summary": "This is the summary of the PDF content..."
   }
   ```

**Notes:**

- **Token Limitations:** The application handles PDFs that exceed the token limitations of the GPT-4 model by splitting the text into chunks and summarizing each chunk individually before combining the summaries.

- **Error Handling:** The application includes error handling for invalid file types and unexpected exceptions.

- **Dependencies:**
  - `fastapi`: For creating the web application.
  - `uvicorn`: For running the ASGI server.
  - `PyPDF2`: For reading and extracting text from PDF files.
  - `openai`: For interacting with the OpenAI GPT-4 model.
  - `tiktoken`: For counting the number of tokens to manage GPT-4 limitations.

- **Security Considerations:** Ensure that the application is secured and does not expose the `OPENAI_API_KEY`. In a production environment, consider additional security measures and input validations.

**Optional Frontend Interface:**

If you wish to create a simple web interface, you can use `Jinja2` templates with FastAPI or build a separate frontend application that interacts with this API.

**Example with FastAPI Templates:**



Create a `templates` directory and add an `upload.html` file for the upload form.

**upload.html:**

```html
<!DOCTYPE html>
<html>
<head>
    <title>Upload PDF for Summarization</title>
</head>
<body>
    <h1>Upload PDF for Summarization</h1>
    <form action="/summarize_pdf/" enctype="multipart/form-data" method="post">
        <input name="file" type="file" accept="application/pdf">
        <input type="submit" value="Upload and Summarize">
    </form>
</body>
</html>
```

This will provide a simple web page where users can upload their PDF files directly through their browser.

**Run the Server with Templates Support:**

Ensure you install `Jinja2`:

```bash
pip install Jinja2
```

Now, when you navigate to `http://127.0.0.1:8000/`, you'll see an upload form.

**Final Remarks:**

This application provides a solid foundation for summarizing PDF contents using GPT-4 and FastAPI. It includes essential features like file upload handling, text extraction from PDFs, token management to comply with model limitations, and error handling to ensure robustness.

Remember to handle your API keys securely and comply with OpenAI's usage policies when deploying and using this application.